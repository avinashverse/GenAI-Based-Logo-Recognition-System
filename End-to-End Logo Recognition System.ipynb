{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import base64\n",
        "import io\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Configuration ---\n",
        "KAGGLE_USERNAME = os.getenv(\"avinashkrishna687\")\n",
        "KAGGLE_KEY = os.getenv(\"ffd83477d431520935fc3ea8bcc91297\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") # This one is CRITICAL for GPT-4o brand identification\n",
        "\n",
        "DATASET_NAME = \"sushovansaha9/flickr-logos-27-dataset\"\n",
        "DATA_DIR = \"data\"\n",
        "MODEL_PATH = \"yolov8_logo_detector.pt\" # Path to save/load the trained YOLOv8 model\n",
        "\n",
        "CLASSES = [\n",
        "    \"Adidas\", \"Apple\", \"BMW\", \"Citroen\", \"Coca Cola\", \"DHL\", \"Fedex\", \"Ferrari\",\n",
        "    \"Ford\", \"Google\", \"Heineken\", \"HP\", \"McDonalds\", \"Mini\", \"Nbc\", \"Nike\",\n",
        "    \"Pepsi\", \"Porsche\", \"Puma\", \"Red Bull\", \"Sprite\", \"Starbucks\", \"Intel\",\n",
        "    \"Texaco\", \"Unisef\", \"Vodafone\", \"Yahoo\"\n",
        "]\n",
        "CLASS_TO_ID = {name: i for i, name in enumerate(CLASSES)}\n",
        "ID_TO_CLASS = {i: name for i, name in enumerate(CLASSES)}\n",
        "\n",
        "# --- Helper function for dataset processing ---\n",
        "def process_annotation_file(annotation_file_path, image_source_dir, image_dest_dir, label_dest_dir):\n",
        "    \"\"\"\n",
        "    Processing single annotation file and moves images/labels to YOLO format.\n",
        "    Args:\n",
        "        annotation_file_path (Path): annotations.txt file.\n",
        "        image_source_dir (Path): containing original images.\n",
        "        image_dest_dir (Path): directory for images in YOLO format.\n",
        "        label_dest_dir (Path): directory for label .txt files in YOLO format.\n",
        "    \"\"\"\n",
        "    print(f\"Processing annotations from {annotation_file_path}...\")\n",
        "\n",
        "    label_dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    for f in label_dest_dir.glob(\"*.txt\"):\n",
        "        os.remove(f)\n",
        "\n",
        "    with open(annotation_file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 7:\n",
        "                continue\n",
        "\n",
        "            img_filename = parts[0]\n",
        "            class_name = parts[1]\n",
        "            try:\n",
        "                x1, y1, x2, y2 = map(int, parts[3:7])\n",
        "            except ValueError:\n",
        "                print(f\"Skipping malformed coordinates in line: {line.strip()}\")\n",
        "                continue\n",
        "\n",
        "            if class_name not in CLASS_TO_ID:\n",
        "                # print(f\"Give Warning: Class '{class_name}' not in predefined classes. Skipping {img_filename}\")\n",
        "                continue # Skip if class is not one of the 27 logos\n",
        "\n",
        "            src_img_path = image_source_dir / img_filename\n",
        "            dest_img_path = image_dest_dir / img_filename\n",
        "\n",
        "            if not src_img_path.exists():\n",
        "                print(f\"Image {src_img_path} not found. Skipping annotation for this image.\")\n",
        "                continue\n",
        "\n",
        "            # Copy image to YOLO structure\n",
        "            try:\n",
        "                shutil.copy(src_img_path, dest_img_path)\n",
        "            except shutil.SameFileError:\n",
        "                pass # File already exists and is the same\n",
        "            except Exception as e:\n",
        "                print(f\"Error copying image {src_img_path}: {e}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Get image dimensions to normalize bounding box for YOLO format\n",
        "            try:\n",
        "                with Image.open(dest_img_path) as img:\n",
        "                    img_w, img_h = img.size\n",
        "            except Exception as e:\n",
        "                print(f\"Could not open image {dest_img_path} for dimensions: {e}. Skipping annotation.\")\n",
        "                continue\n",
        "\n",
        "            # Convert to YOLO format (normalized x_center, y_center, width, height)\n",
        "            box_x_center = ((x1 + x2) / 2) / img_w\n",
        "            box_y_center = ((y1 + y2) / 2) / img_h\n",
        "            box_width = (x2 - x1) / img_w\n",
        "            box_height = (y2 - y1) / img_h\n",
        "\n",
        "            class_id = CLASS_TO_ID[class_name]\n",
        "\n",
        "            label_filename = Path(img_filename).stem + \".txt\"\n",
        "            with open(label_dest_dir / label_filename, 'a') as f: # 'a' to append for multiple objects in one image\n",
        "                f.write(f\"{class_id} {box_x_center:.6f} {box_y_center:.6f} {box_width:.6f} {box_height:.6f}\\n\")\n",
        "    print(f\"Finished processing {annotation_file_path}.\")\n",
        "\n",
        "\n",
        "#Dataset Download and Preparation Logic & YOLOv8 Training\n",
        "def setup_dataset_and_train_model():\n",
        "    \"\"\"\n",
        "    prepaing dataset, and training the YOLOv8 model.\n",
        "    \"\"\"\n",
        "    yolo_data_root = Path(DATA_DIR) / \"yolov8_data\"\n",
        "    data_yaml_path = yolo_data_root / \"data.yaml\"\n",
        "\n",
        "    # Create necessary directories if they don't exist\n",
        "    yolo_data_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    # Check if trained model and data.yaml exist (implies previous setup was successful)\n",
        "    if os.path.exists(MODEL_PATH) and os.path.exists(data_yaml_path):\n",
        "        print(f\"Model ({MODEL_PATH}) and data.yaml ({data_yaml_path}) found. Skipping dataset prep and training.\")\n",
        "        return str(data_yaml_path)\n",
        "\n",
        "    # --- Kaggle Download Section (only if model/data.yaml not found) ---\n",
        "    kaggle_username = os.getenv(\"KAGGLE_USERNAME\")\n",
        "    kaggle_key = os.getenv(\"KAGGLE_KEY\")\n",
        "\n",
        "    if not kaggle_username or not kaggle_key:\n",
        "        print(\"Kaggle credentials (KAGGLE_USERNAME, KAGGLE_KEY) not found as environment variables.\")\n",
        "        print(\"To train the model from scratch, set these environment variables.\")\n",
        "        print(\"For Hugging Face Spaces, it's better to upload the trained model directly to the repo.\")\n",
        "        # Create a dummy data.yaml if no Kaggle credentials and no existing model/data.yaml\n",
        "        if not os.path.exists(data_yaml_path):\n",
        "            print(\"Creating a dummy data.yaml for fallback.\")\n",
        "            # Ensure parent directory exists before opening the file\n",
        "            data_yaml_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            data_yaml_content = f\"\"\"\n",
        "path: .\n",
        "train: .\n",
        "val: .\n",
        "nc: {len(CLASSES)}\n",
        "names: {CLASSES}\n",
        "\"\"\"\n",
        "            with open(data_yaml_path, \"w\") as f:\n",
        "                f.write(data_yaml_content)\n",
        "        return str(data_yaml_path) # Return path even if it's a incomplete\n",
        "\n",
        "    print(\"Authenticating Kaggle API...\")\n",
        "    os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
        "    os.environ['KAGGLE_KEY'] = kaggle_key\n",
        "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "    print(\"Kaggle API authenticated.\")\n",
        "\n",
        "    print(f\"Downloading dataset '{DATASET_NAME}' to '{DATA_DIR}'...\")\n",
        "    if not os.path.exists(DATA_DIR):\n",
        "        os.makedirs(DATA_DIR)\n",
        "\n",
        "    dataset_zip_path = Path(DATA_DIR) / f\"{DATASET_NAME.split('/')[-1]}.zip\"\n",
        "    if not dataset_zip_path.exists():\n",
        "        api.dataset_download_files(DATASET_NAME, path=DATA_DIR, unzip=False)\n",
        "        print(\"Dataset ZIP downloaded.\")\n",
        "    else:\n",
        "        print(\"Dataset ZIP already exists, skipping download.\")\n",
        "\n",
        "    print(f\"Unzipping dataset to {DATA_DIR}...\")\n",
        "    unzipped_dir = Path(DATA_DIR) / \"Flickr_Logos_27_dataset\"\n",
        "    if not unzipped_dir.exists():\n",
        "        with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DATA_DIR)\n",
        "        print(\"Dataset unzipped.\")\n",
        "    else:\n",
        "        print(\"Dataset already unzipped, skipping unzipping.\")\n",
        "\n",
        "    # Prepare directories for YOLOv8\n",
        "    print(\"Creating YOLOv8 data structure...\")\n",
        "    (yolo_data_root / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "    (yolo_data_root / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "    (yolo_data_root / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "    (yolo_data_root / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "    print(\"YOLOv8 data directories created.\")\n",
        "\n",
        "    base_path = unzipped_dir\n",
        "    train_images_src = base_path / \"FlickrLogos-27_training\" / \"images\"\n",
        "    train_anno_src = base_path / \"FlickrLogos-27_training\" / \"annotations.txt\"\n",
        "    query_images_src = base_path / \"FlickrLogos-27_query\" / \"images\"\n",
        "    query_anno_src = base_path / \"FlickrLogos-27_query\" / \"annotations.txt\"\n",
        "\n",
        "    process_annotation_file(train_anno_src, train_images_src, yolo_data_root / \"images\" / \"train\", yolo_data_root / \"labels\" / \"train\")\n",
        "    process_annotation_file(query_anno_src, query_images_src, yolo_data_root / \"images\" / \"val\", yolo_data_root / \"labels\" / \"val\")\n",
        "\n",
        "    # Create data.yaml for YOLOv8\n",
        "    data_yaml_content = f\"\"\"\n",
        "path: {yolo_data_root.resolve()}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: {len(CLASSES)}\n",
        "names: {CLASSES}\n",
        "\"\"\"\n",
        "    # Ensure parent directory exists before opening the file\n",
        "    data_yaml_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(data_yaml_path, \"w\") as f:\n",
        "        f.write(data_yaml_content)\n",
        "    print(\"data.yaml created for YOLOv8 training.\")\n",
        "\n",
        "    # --- Train YOLOv8 Model ---\n",
        "    print(\"Starting YOLOv8 model training...\")\n",
        "    try:\n",
        "        model = YOLO('yolov8n.pt') # Load a pretrained nano model for faster inference, Optimized training parameters\n",
        "\n",
        "        results = model.train(\n",
        "            data=str(data_yaml_path),\n",
        "            epochs=100, # Increased epochs for better performance on Colab.\n",
        "            imgsz=640, # Image size for training\n",
        "            batch=16, # Batch size (adjust based on GPU memory)\n",
        "            optimizer='AdamW', # AdamW optimizer often performs well\n",
        "            lr0=0.01, # Initial learning rate\n",
        "            lrf=0.01, # Final learning rate as a fraction of lr0\n",
        "            momentum=0.937, # SGD momentum\n",
        "            weight_decay=0.0005, # L2 regularization\n",
        "            warmup_epochs=3.0, # Warmup for initial learning rate\n",
        "            patience=50, # Early stopping patience (stop if no improvement for 50 epochs)\n",
        "            augment=True, # Enable default augmentations (e.g., flip, mosaic, mixup)\n",
        "            cos_lr=True, # Use cosine learning rate scheduler\n",
        "            val=True, # Validate during training\n",
        "            workers=8, # Number of Dataloader workers (adjust based on CPU cores)\n",
        "            device=0, # Use GPU if available (0 for first GPU)\n",
        "            # plots=False, # Disable plots during training to save resources if not needed\n",
        "            # save_period=10 # Save checkpoint every 10 epochs\n",
        "        )\n",
        "        trained_model_source_path = Path(\"runs/detect/train/weights/best.pt\")\n",
        "        if trained_model_source_path.exists():\n",
        "            shutil.copy(trained_model_source_path, MODEL_PATH)\n",
        "            print(f\"Trained model saved to {MODEL_PATH}\")\n",
        "        else:\n",
        "            print(\"Error: Trained model not found after training.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during YOLOv8 training: {e}\")\n",
        "        print(\"Proceeding to inference. If model was not saved, it will fall back to default YOLOv8n.\")\n",
        "\n",
        "    return str(data_yaml_path) # Return path to data.yaml\n",
        "\n",
        "# Global variables for models to ensure they are loaded only once\n",
        "yolo_model_instance = None\n",
        "openai_client_instance = None\n",
        "default_font = None # To store a loaded font for drawing text\n",
        "\n",
        "# Initialize models (YOLO and OpenAI)\n",
        "def initialize_models():\n",
        "    \"\"\"Initializes the YOLO model and OpenAI client globally.\"\"\"\n",
        "    global yolo_model_instance, openai_client_instance, default_font\n",
        "\n",
        "    if yolo_model_instance is None:\n",
        "        try:\n",
        "            if os.path.exists(MODEL_PATH):\n",
        "                print(f\"Loading YOLO model from {MODEL_PATH}...\")\n",
        "                yolo_model_instance = YOLO(MODEL_PATH)\n",
        "                print(\"YOLO model loaded.\")\n",
        "            else:\n",
        "                print(f\"Trained YOLO model not found at {MODEL_PATH}. loading default yolov8n.pt for inference (less accurate).\")\n",
        "                yolo_model_instance = YOLO('yolov8n.pt') # Fallback to a pre-trained general model\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading YOLO model: {e}\")\n",
        "            yolo_model_instance = None # Set to None if loading fails\n",
        "\n",
        "    if openai_client_instance is None and OPENAI_API_KEY:\n",
        "        try:\n",
        "            openai_client_instance = OpenAI(OPENAI_API_KEY)\n",
        "            print(\"OpenAI client initialized.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing OpenAI client: {e}\")\n",
        "            openai_client_instance = None\n",
        "    elif not OPENAI_API_KEY:\n",
        "        print(\"OPENAI_API_KEY not set. and will not be used for brand identification.\")\n",
        "\n",
        "\n",
        "    if default_font is None:\n",
        "        try:\n",
        "\n",
        "            default_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
        "        except IOError:\n",
        "\n",
        "            default_font = ImageFont.load_default()\n",
        "        print(\"Font for drawing labels loaded.\")\n",
        "\n",
        "\n",
        "# GPT-4o Vision API Call\n",
        "def get_brand_name_from_gpt4o(cropped_image_pil):\n",
        "    \"\"\"\n",
        "    Sending a cropped image to GPT-4o Vision API to identify the brand.\n",
        "    Args:\n",
        "        cropped_image_pil (PIL.Image.Image): The cropped image of the logo.\n",
        "    Returns:\n",
        "        str: The identified brand name or an error/unknown message.\n",
        "    \"\"\"\n",
        "    if not openai_client_instance:\n",
        "        return \"N/A (API Key Missing / Client Error)\"\n",
        "\n",
        "    buffered = io.BytesIO()\n",
        "    cropped_image_pil.save(buffered, format=\"PNG\")\n",
        "    img_base64 = base66.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        response = openai_client_instance.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"What brand logo is clearly visible in this image? Respond with only the brand name. If no clear brand logo is present or I am unsure, respond with 'Unknown'.\"},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\", \"detail\": \"low\"}} # \"low\" detail for faster processing, lower cost\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=20, # Keep max_tokens low for concise, direct responses\n",
        "            temperature=0.0, # Low temperature for factual, deterministic output\n",
        "        )\n",
        "        brand_name = response.choices[0].message.content.strip()\n",
        "        return brand_name\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling GPT-4o: {e}\")\n",
        "        return \"Error (API Call Failed)\"\n",
        "\n",
        "# Gradio Inference Function\n",
        "def process_image_with_detection(image_pil):\n",
        "    \"\"\"\n",
        "    Processes an uploaded image: runs YOLOv8 detection, sends crops to GPT-4o,\n",
        "    and returns an annotated image.\n",
        "    Args:\n",
        "        image_pil (PIL.Image.Image): The input image from Gradio.\n",
        "    Returns:\n",
        "        tuple: (annotated_image_pil, list_of_annotations_for_gradio)\n",
        "    \"\"\"\n",
        "    if yolo_model_instance is None:\n",
        "        gr.Warning(\"YOLO model not loaded. Please check logs for errors or ensure model is trained\")\n",
        "        return image_pil, [] # Return original image if model not loaded\n",
        "\n",
        "    print(\"Running YOLOv8 inference...\")\n",
        "    start_time_yolo = time.time()\n",
        "\n",
        "    results = yolo_model_instance(image_pil, conf=0.3, iou=0.5, verbose=False)\n",
        "    end_time_yolo = time.time()\n",
        "    print(f\"YOLOv8 inference took {end_time_yolo - start_time_yolo:.2f} seconds.\")\n",
        "\n",
        "    annotated_image_pil = image_pil.copy()\n",
        "    draw = ImageDraw.Draw(annotated_image_pil)\n",
        "\n",
        "    annotations = [] # List for Gradio AnnotatedImage component\n",
        "\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            confidence = box.conf[0]\n",
        "\n",
        "            # Ensure coordinates are within image bounds to prevent cropping errors\n",
        "            x1 = max(0, x1)\n",
        "            y1 = max(0, y1)\n",
        "            x2 = min(image_pil.width, x2)\n",
        "            y2 = min(image_pil.height, y2)\n",
        "\n",
        "            if x2 <= x1 or y2 <= y1: # Skip invalid or zero-area boxes\n",
        "                continue\n",
        "\n",
        "            cropped_image = image_pil.crop((x1, y1, x2, y2))\n",
        "\n",
        "            print(f\"Calling GPT-4o for brand identification on cropped region {x1, y1, x2, y2}...\")\n",
        "            start_time_gpt = time.time()\n",
        "            brand_name = get_brand_name_from_gpt4o(cropped_image)\n",
        "            end_time_gpt = time.time()\n",
        "            print(f\"GPT-4o call took {end_time_gpt - start_time_gpt:.2f} seconds. Identified: {brand_name}\")\n",
        "\n",
        "            # Add annotation for Gradio's AnnotatedImage\n",
        "            annotations.append(((x1, y1, x2, y2), f\"{brand_name} ({confidence:.2f})\"))\n",
        "\n",
        "\n",
        "    return annotated_image_pil, annotations\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_6c8RW_yfBA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main application logic\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Application starting...\")\n",
        "    print(\"Running setup_dataset_and_train_model (skips if model/data.yaml found)...\")\n",
        "    setup_dataset_and_train_model()\n",
        "\n",
        "    # Initialize models(YOLO and OpenAI client)after setup\n",
        "    print(\"Initializing models (YOLO and OpenAI client)\")\n",
        "    initialize_models()\n",
        "\n",
        "    print(\"Creating Gradio interface\")\n",
        "    iface = gr.Interface(\n",
        "        fn=process_image_with_detection,\n",
        "        inputs=gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
        "        outputs=gr.AnnotatedImage(label=\"Detected Logos and Brands\", show_legend=True, color_map={\n",
        "            # We can define specific colors for known brands here for consistency\n",
        "            # Ex \"Adidas\": \"#000000\", \"Nike\": \"#FF0000\"\n",
        "        }),\n",
        "        title=\"End-to-End Logo Recognition System\",\n",
        "        description=(\n",
        "            \"<p>Upload an image to detect logos using a fine-tuned YOLOv8 model. \"\n",
        "            \"For each detected logo, the cropped region is sent to OpenAI's GPT-4o \"\n",
        "            \"to identify the brand name.</p>\"\n",
        "\n",
        "        ),\n",
        "        allow_flagging=\"never\", # Disable flagging feature\n",
        "        examples=[\n",
        "            # Add paths to example images\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"Launching Gradio application. Check the public URL for access.\")\n",
        "    iface.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "0tkFsa-Rp0_w",
        "outputId": "cff1450c-539c-4304-dce4-134c3c1e0fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Application starting...\n",
            "Running setup_dataset_and_train_model (skips if model/data.yaml found)...\n",
            "Kaggle credentials (KAGGLE_USERNAME, KAGGLE_KEY) not found as environment variables.\n",
            "To train the model from scratch, set these environment variables.\n",
            "For Hugging Face Spaces, it's better to upload the trained model directly to the repo.\n",
            "Initializing models (YOLO and OpenAI client)\n",
            "OPENAI_API_KEY not set. GPT-4o will not be used for brand identification.\n",
            "Creating Gradio interface\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio application. Check the public URL for access.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://acc24cfe2072740cc0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://acc24cfe2072740cc0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running YOLOv8 inference...\n",
            "YOLOv8 inference took 0.32 seconds.\n",
            "Calling GPT-4o for brand identification on cropped region (1420, 979, 1599, 1094)...\n",
            "GPT-4o call took 0.00 seconds. Identified: N/A (API Key Missing / Client Error)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}